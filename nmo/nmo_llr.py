#!/usr/bin/env python


from argparse import ArgumentParser, ArgumentDefaultsHelpFormatter
from copy import deepcopy

from pisa.core.analysis import Analysis
from pisa.core.distribution_maker import DistributionMaker
from pisa.utils.config_parser import parse_pipeline_config
from pisa.utils.fileio import from_file, to_file
from pisa.utils.log import logging, set_verbosity
from pisa.utils.resources import find_resource


def get_fiducial_maker(truth, hypo, minimizer_settings):
    """
    Performs a fiducial fit to the "true" distribution generated by `truth`
    (whether this comes from MC or data) to find the best fit parameters under
    the hypothesis set up in `hypo_settings`.

    Parameters
    ----------
    truth : DistributionMaker
        The DistributionMaker object from which the truth distribution is
        drawn.

    hypo_config : OrderedDict
        The parsed config file with which to define the hypothesis.
        We pass the config so that we can make a copy of it and replace the
        free parameter values with the best fit ones found in this function.

    minimizer_settings : string
        Location of the file minimizer settings file

    Returns
    -------
    A DistributionMaker object set up to the best fit parameters under the
    hypothesis set in hypo.

    """
    # Make a deecopy that we will modify later for return
    hypo_ = deepcopy(hypo_settings)
    hypo_maker = DistributionMaker(hypo)

    # Create the analysis object and then do the fiducial fit
    fid_analysis = Analysis(
        data_maker=truth,
        template_maker=hypo_maker,
        metric='llh',
        minimizer_settings=minimizer_settings
    )
    fid_analysis.data_maker.get_outputs('asimov')
    best_fit = fid_analysis.find_best_fit()

    # Set the parameters in fid_maker to those from the best fit
    fid_maker = DistributionMaker(fid_config)
    for pname in hypo_maker.params.free.names:
        fid_maker.params[pname].value = best_fit[pname]

    return fid_maker


def nmo_analysis(truth, template_settings, minimizer_settings, trials=1,
                 injected=None):
    """Run the NMO analysis assuming the truth provided. This can be either
    from a simulation or from data, but will be an instance of
    DistributionMaker. `template_settings` is used to fit to pseudo data
    constructed from the truth.

    Parameters
    ----------
    truth : DistributionMaker
        The DistributionMaker object from which the truth is drawn.

    template_settings : string
        A string pointing to the location of a pipeline settings ini file from
        which to construct all of the fit templates.

    minimizer_settings : string
        A string pointing to the location of the file containing the settings
        that define how the minimizer operates.

    trials : integer
        The number of pseudo-experiments to be created.

    injected : string or None
        A string with the injected true ordering (either 'NO' or 'IO'), if
        known. Otherwise, set `injected` to None and each ordering will be
        injected..

    Returns
    -------
    A dictionary object containing the output of the NMO analysis

    """
    if injected is None:
        injected = ''
    injected = injected.upper().strip()
    assert injected in ['', 'NO', 'IO']

    # First we need to make the DisitrubitonMaker objects from which to
    # construct the NO and IO hypotheses.
    NO_hypo_config = from_file(template_settings)
    NO_hypo_config.set('stage:osc', 'param_selector', 'nh')
    NO_hypo_parsed = parse_pipeline_config(NO_hypo_config)
    NO_hypo_maker = DistributionMaker(NO_hypo_parsed)

    IO_hypo_config = from_file(template_settings)
    IO_hypo_config.set('stage:osc', 'param_selector', 'ih')
    IO_hypo_parsed = parse_pipeline_config(IO_hypo_config)
    IO_hypo_maker = DistributionMaker(IO_hypo_parsed)

    # Then we do the initial fiducial fits to get best fit assuming NO and IO
    if injected != 'IO':
        logging.info('>> fiducial_NO is injected')
        NO_fid_maker = DistributionMaker(NO_hypo_parsed)

        # Perform fit to truth to find best fit to IO
        logging.info('>> fiducial_IO will be fit for')
        IO_fid_maker = fiducial_maker(truth=truth,
                                      hypo=IO_hypo_parsed,
                                      minimizer_settings=minimizer_settings)
    elif injected != 'NO':
        logging.info('>> fiducial_IO is injected')
        IO_fid_maker = DistributionMaker(IO_hypo_parsed)
        # Perform fit to truth to find best fit to NO
        logging.info('>> fiducial_NO will be fit for')
        NO_fid_maker = fiducial_maker(truth=truth,
                                      hypo=NO_hypo_parsed,
                                      minimizer_settings=minimizer_settings)

    all_results = {}
    fid_keys = ['fiducial_NO', 'fiducial_IO']
    fid_makers = [NO_fid_maker, IO_fid_maker]
    for fid_key, fid_maker in zip(fid_keys, fid_makers):
        logging.info('>> Testing fiducial model %s' %fid_key)
        # Set up the analysis object for the trials
        # The template_maker is overwritten in the llr method so we can
        # set it arbitrarily here. NO is chosen just because.
        analysis = Analysis()
        data_maker=fid_maker,
                            template_maker=NO_hypo_parsed,
                            metric='llh',
                            minimizer_settings=minimizer_settings)
        analysis.minimizer_settings = from_file(args.minimizer_settings)

        results = []
        for trial in range(1, trials+1):
            logging.info('>>> Running trial %i of %i' %(trial, trials))
            data = data_maker.generate_pseudodata('poisson')
            result = analysis.llr(template_maker0=NO_hypo_parsed,
                                  template_maker1=IO_hypo_maker,
                                  hypo0='NO',
                                  hypo1='IO')
            results.append(result)
        all_results[fid_key] = results

    return all_results


if __name__ == '__main__':
    parser = ArgumentParser(
        description='''Perform the LLR analysis for calculating the NMO
        sensitivity of the distribution made from data-settings compared with
        hypotheses generated from template-settings.

        Currently the output should be a json file containing the dictionary
        of best fit and likelihood values.'''
    )
    parser.add_argument(
        '--alt-hypo-pipeline', required=True,
        type=str, action='append', default=None, metavar='PIPELINE_CFG',
        help='''Settings for the generation of alternate hypothesis
        distributions; repeat this argument to specify multiple pipelines.'''
    )
    parser.add_argument(
        '--alt-hypo-param-selections',
        type=str, default=None, metavar='PARAM_SELECTOR_LIST',
        help='''Comma-separated (no spaces) list of param selectors to apply to
        the alt hypothesis distribution maker's pipelines.'''
    )
    parser.add_argument(
        '--null-hypo-pipeline',
        type=str, action='append', default=None, metavar='PIPELINE_CFG',
        help='''Settings for the generation of null hypothesis distributions;
        repeat this argument to specify multiple pipelines. If omitted, the
        same settings as specified for --alt-hypo-pipeline are used to generate
        the null hypothesis distributions (and so you have to use the
        --null-hypo-param-selections argument to generate a hypotheses distinct
        from the alt hypothesis while using alt hypo's distribution maker).'''
    )
    parser.add_argument(
        '--null-hypo-param-selections',
        type=str, default=None, metavar='PARAM_SELECTOR_LIST',
        help='''Comma-separated (no spaces) list of param selectors to apply to
        the null hypothesis distribution maker's pipelines.'''
    )
    parser.add_argument(
        '--data-pipeline',
        type=str, action='append', default=None, metavar='PIPELINE_CFG',
        help='''Settings for the generation of "data" distributions; repeat
        this argument to specify multiple pipelines. If omitted, the same
        settings as specified for --alt-hypo-pipeline are used to generate data
        distributions (i.e., data is assumed to come from the alternate
        hypothesis.'''
    )
    parser.add_argument(
        '--data-param-selections',
        type=str, default=None, metavar='PARAM_SELECTOR_LIST',
        help='''Comma-separated list of param selectors to apply to the data
        distribution maker's pipelines. If neither --data-pipeline nor
        --data-param-selections are specified, *both* are copied from
        --alt-hypo-pipeline and --alt-param-selections, respectively. However,
        if --data-pipeline is specified while --data-param-selections is not,
        then the param selections in the pipeline config file(s) specified are
        used to produce data distributions.'''
    )
    parser.add_argument(
        '-m', '--minimizer-settings',
        type=str, metavar='MINIMIZER_CFG', required=True,
        help='''Settings related to the optimizer used in the LLR analysis.'''
    )
    parser.add_argument(
        '--fluctuate-data',
        type=bool, action='store_true'
        help='''Apply fluctuations to the data distribution. This should *not*
        be set for analyzing "real" (measured) data, and it is common to not
        use this feature even for Monte Carlo analysis. If this is not set,
        --num-data-trials is forced to 1.'''
    parser.add_argument(
        '--num-data-trials',
        type=int, default=1,
        help='''When performing Monte Carlo analysis, set to > 1 to produce
        multiple pseudodata distributions from the data distribution maker's
        Asimov data distribution. This is overridden if --fluctuate-data is not
        set (since each data distribution will be identical if it is not
        fluctuated). This is typically left at 1 (i.e., the Asimov distribution
        is assumed to be representative.'''
    )
    parser.add_argument(
        '--fluctuate-fid-data',
        type=bool, action='store_true'
        help='''Apply fluctuations to the fiducaial data distributions. If this
        is not set, --num-fid-data-trials is forced to 1.'''
    parser.add_argument(
        '-n', '--num-fid-data-trials',
        type=int, default=1,
        help='''Number of fiducial pseudodata trials to run. In our experience,
        it takes ~10^3-10^5 fiducial psuedodata trials to achieve low
        uncertainties on the resulting significance, though that exact number
        will vary based upon the details of an analysis.'''
    )
    parser.add_argument(
        '-o', '--outdir',
        metavar='DIR', required=True, type=str,
        help='Directory into which to store results.'
    )
    parser.add_argument(
        '-v', action='count', default=None,
        help='set verbosity level'
    )
    args = parser.parse_args()
    set_verbosity(args.v)

    template_config = from_file(args.template_settings)
    template_parsed = parse_pipeline_config(NO_data_config)
    template_maker = DistributionMaker(pipelines=template_parsed)

    if args.data_settings is None:
        logging.warn('No data_settings provided. It is therefore assumed '
                     'that you want to do a full MC study, and so results '
                     'for both true_NO and true_IO will be produced. If you do '
                     'not want this, please specify --data-settings for your '
                     'preferred truth or for real data.')
        all_results = {}

        NO_data_config = deepcopy(template_config)
        NO_data_config.set('stage:osc', 'param_selector', 'nh')
        NO_data_parsed = parse_pipeline_config(NO_data_config)

        IO_data_config = deepcopy(template_config)
        IO_data_config.set('stage:osc', 'param_selector', 'ih')
        IO_data_parsed = parse_pipeline_config(IO_data_config)

        logging.info('> Running NO as truth')
        NO_data_maker = DistributionMaker(pipelines=NO_data_parsed)
        all_results['true_NO'] = nmo_analysis(
            truth=NO_data_maker,
            template_settings=args.template_settings,
            minimizer_settings=args.minimizer_settings,
            trials=args.num_trials,
            injected='NO'
        )

        logging.info('> Running IO as truth')
        IO_data_maker = DistributionMaker(IO_data_parsed)
        all_results['true_IO'] = nmo_analysis(
            truth=IO_data_maker,
            template_settings=args.template_settings,
            minimizer_settings=args.minimizer_settings,
            trials=args.num_trials,
            injected='IO'
        )

    else:
        all_results = {}
        logging.info('> Running user-specified as truth')
        data_maker = DistributionMaker(args.data_settings)
        all_results['true_data'] = nmo_analysis(
            truth=data_maker,
            template_settings=args.template_settings,
            minimizer_settings=args.minimizer_settings,
            trials=args.num_trials
        )

    logging.info('Output will be saved to %s' %args.outfile)
    to_file(all_results, args.outfile)
