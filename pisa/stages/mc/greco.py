"""
The purpose of this stage is to load in events generated from Monte Carlo
simulations.

This service in particular reads in from files belonging to the GRECO
event sample. More information about this event sample can be found on
https://wiki.icecube.wisc.edu/index.php/IC86_Tau_Appearance_Analysis
"""
from operator import add

import numpy as np
import pint; ureg = pint.UnitRegistry()
from uncertainties import unumpy as unp

from pisa.core.stage import Stage
from pisa.core.map import Map, MapSet
from pisa.core.binning import OneDimBinning, MultiDimBinning
from pisa.utils.fileio import from_file
from pisa.utils.flavInt import NuFlavIntGroup, FlavIntDataGroup
from pisa.utils.flavInt import BarSep, flavintGroupsFromString
from pisa.utils.log import logging
from pisa.utils.profiler import profile


class greco(Stage):
    """mc service to load in events from the GRECO event sample.

    Parameters
    ----------
    params: ParamSet of sequence with which to instantiate a ParamSet
        Parameters which set everything besides the binning

        Parameters required by this service are
            * mc_sample_config : filepath
                Filepath to event sample configuration

            * livetime : ureg.Quantity
                Desired lifetime.

    output_binning : MultiDimBinning or convertible thereto
        The binning desired for the output maps.

    transform_groups : string
        Specifies which particles/interaction types to use for computing the
        transforms.

    error_method : None, bool, or string
        If None, False, or empty string, the stage does not compute errors for
        the transforms and does not apply any (additional) error to produce its
        outputs. (If the inputs already have errors, these are propagated.)

    debug_mode : None, bool, or string
        If None, False, or empty string, the stage runs normally.
        Otherwise, the stage runs in debug mode. This disables caching (forcing
        recomputation of any nominal transforms, transforms, and outputs).

    disk_cache : None, str, or DiskCache
        If None, no disk cache is available.
        If str, represents a path with which to instantiate a utils.DiskCache
        object. Must be concurrent-access-safe (across threads and processes).

    transforms_cache_depth
    outputs_cache_depth : int >= 0

    Output Names
    ----------
    The `outputs` container generated by this service will be objects with the
    following `name` attribute:
        * 'nue_cc+nuebar_cc'
        * 'numu_cc+numubar_cc'
        * 'nutau_cc+nutaubar_cc'
        * 'nuall_nc+nuallbar_nc'
        * 'muongun'
        * 'noise'

    """
    def __init__(self, params, output_binning, output_names,
                 error_method=None, debug_mode=None, disk_cache=None, 
                 memcache_deepcopy=True, transforms_cache_depth=20,
                 outputs_cache_depth=20):
        expected_params = (
            'mc_sample_config', 'livetime', 'weight'
        )

        self.output_groups = flavintGroupsFromString(output_names)
        with BarSep('_'):
            output_names = [str(f) for f in self.output_groups]

        super(self.__class__, self).__init__(
            use_transforms=False,
            params=params,
            expected_params=expected_params,
            output_names=output_names,
            error_method=error_method,
            debug_mode=debug_mode,
            disk_cache=disk_cache,
            memcache_deepcopy=memcache_deepcopy,
            outputs_cache_depth=outputs_cache_depth,
            transforms_cache_depth=transforms_cache_depth,
            output_binning=output_binning
        )

        self.config = from_file(self.params['mc_sample_config'].value)
        self.include_attrs_for_hashes('output_groups')

    @staticmethod
    def _histogram(events, binning, weights=None, errors=False, **kwargs):
        """Histogram the events given the input binning."""
        if isinstance(binning, OneDimBinning):
            binning = MultiDimBinning([binning])
        elif not isinstance(binning, MultiDimBinning):
            raise TypeError('Unhandled type %s for `binning`.' %type(binning))
        if not isinstance(events, dict):
            raise TypeError('Unhandled type %s for `events`.' %type(events))

        bin_names = binning.names
        bin_edges = [edges.m for edges in binning.bin_edges]
        for name in bin_names:
            if not events.has_key(name):
                if 'coszen' in name and events.has_key('zenith'):
                    events[name] = np.cos(events['zenith'])
                else:
                    raise AssertionError('Input events object does not have '
                                         'key {0}'.format(name))

        sample = [events[colname] for colname in bin_names]
        hist, edges = np.histogramdd(
            sample=sample, weights=weights, bins=bin_edges
        )
        if errors:
            hist2, edges = np.histogramdd(
                sample=sample, weights=np.square(weights), bins=bin_edges
            )
            hist = unp.uarray(hist, np.sqrt(hist2))

        return Map(hist=hist, binning=binning, **kwargs)

    @profile
    def _compute_outputs(self, inputs=None):
        """Compute nominal histograms for output channels."""
        def parse(string):
            return string.replace(' ', '').split(',')
        event_types = parse(self.config.get('general', 'event_type'))

        # TODO(shivesh): some sort of hashing
        nu_fidg = []
        for ev_type in event_types:
            if 'neutrino' in ev_type:
                flavours = parse(self.config.get(ev_type, 'flavours'))
                sys_list = parse(self.config.get(ev_type, 'sys_list'))
                base_suffix = parse(self.config.get(ev_type, 'basesuffix'))[0]

                for idx, flav in enumerate(flavours):
                    f = int(flav)
                    cc_grps = NuFlavIntGroup(NuFlavIntGroup(f,-f).ccFlavInts())
                    nc_grps = NuFlavIntGroup(NuFlavIntGroup(f,-f).ncFlavInts())
                    flav_fidg = FlavIntDataGroup(
                        flavint_groups=[cc_grps, nc_grps]
                    )
                    prefixes = []
                    for sys in sys_list:
                        ev_sys = ev_type + ':' + sys
                        nominal = self.config.get(ev_sys, 'nominal')
                        ev_sys_nom = ev_sys + ':' + nominal
                        prefixes.append(self.config.get(ev_sys_nom,
                                                        'file_prefix'))
                    if len(set(prefixes)) > 1:
                        raise AssertionError(
                            'Choice of nominal file is ambigous. Nominal '
                            'choice of systematic parameters must coincide '
                            'with one and only one file. Options found are: '
                            '{0}'.format(prefixes)
                        )
                    file_prefix = flav + list(set(prefixes))[0]
                    events_file = self.config.get('general', 'datadir') + \
                            base_suffix + file_prefix

                    events = from_file(events_file)
                    cc_mask = events['ptype'] > 0
                    nc_mask = events['ptype'] < 0

                    flav_fidg[cc_grps] = {var: events[var][cc_mask]
                                          for var in events.iterkeys()}
                    flav_fidg[nc_grps] = {var: events[var][nc_mask]
                                          for var in events.iterkeys()}
                    nu_fidg.append(flav_fidg)
                nu_fidg = reduce(add, nu_fidg)

        output_fidg = nu_fidg.transform_groups(self.output_groups)

        livetime = self.params['livetime'].to(ureg.s).m
        logging.info('Weighting with a livetime of {0} s'.format(livetime))
        outputs = []
        for fig in output_fidg.iterkeys():
            if self.params['weight'].value:
                weights = output_fidg[fig]['weight'] * livetime
            else: weights = None
            outputs.append(self._histogram(
                events  = output_fidg[fig],
                binning = self.output_binning,
                weights = weights,
                errors  = True,
                name    = fig,
            ))

        return MapSet(maps=outputs, name='greco maps')

    def validate_params(self, params):
        assert isinstance(params['mc_sample_config'].value, basestring)
        assert isinstance(params['weight'].value, bool)
        assert isinstance(params['livetime'].value, pint.quantity._Quantity)
