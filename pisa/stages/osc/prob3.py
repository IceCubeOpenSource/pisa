# authors: T.Arlen, J.Lanfranchi, P.Eller, T.Stuttard
# date:   Oct 23, 2017


from __future__ import division

import os, sys

import numpy as np

from scipy.interpolate import RectBivariateSpline

from pisa import FTYPE, C_FTYPE, C_PRECISION_DEF
from pisa.core.binning import MultiDimBinning
from pisa.core.param import ParamSet, ParamSelector
from pisa.core.stage import Stage
from pisa.core.transform import BinnedTensorTransform, TransformSet
from pisa.utils.resources import find_resource
from pisa.stages.osc.prob3cc.BargerPropagator import BargerPropagator
from pisa.utils.comparisons import normQuant
from pisa.utils.profiler import profile
from pisa.utils.log import logging
from pisa.stages.osc.layers import Layers
from pisa.stages.osc.osc_params import OscParams


__all__ = ['prob3']


SIGFIGS = 12 
"""Significant figures for determining if numbers and quantities normalised
(using pisa.utils.comparisons.normQuant) are equal. Make sure this is less than
the numerical precision that calculations are being performed in to have the
desired effect that "essentially equal" things evaluate to be equal."""


class prob3(Stage):

    """Neutrino oscillations calculation via Prob3.

    Parameters
    ----------
    params : ParamSet
        All of the following param names (and no more) must be in `params`.
        Earth parameters:
            * earth_model : str (resource location with earth model file)
            * YeI : float (electron fraction, inner core)
            * YeM : float (electron fraction, mantle)
            * YeO : float (electron fraction, outer core)
        Detector parameters:
            * detector_depth : float >= 0
            * prop_height
        Oscillation parameters:
            * deltacp
            * deltam21
            * deltam31
            * theta12
            * theta13
            * theta23
        Nutau (and nutaubar) normalization (binned transform mode only):
            * nutau_norm

    input_binning : MultiDimBinning
    output_binning : MultiDimBinning
    transforms_cache_depth : int >= 0
    outputs_cache_depth : int >= 0
    debug_mode : bool
    use_gpu : Use a GPU to perform the oscillation calculation (otherwise use CPU)
    gpu_id : If running on a system with multiple GPUs, it will choose
             the one with gpu_id. Otherwise, defaults to 0
    use_spline : Instead of calculating probability for individual events, generate a probability spline in E-coszen space and sample from that (faster, less precise)
    spline_binning : The binning to use for the spline, must have "true_energy" and "true_coszen" dimensions

    Input Names
    -----------
    The `inputs` container must include objects with `name` attributes:
      * 'nue'
      * 'numu'
      * 'nuebar'
      * 'numubar'

    Output Names
    ------------
    The `outputs` container generated by this service will be objects with the
    following `name` attribute:
      * 'nue'
      * 'numu'
      * 'nutau'
      * 'nuebar'
      * 'numubar'
      * 'nutaubar'

    """



    # Define CUDA kernel
    KERNEL_TEMPLATE = '''//CUDA//
    #define %(C_PRECISION_DEF)s
    #define fType %(C_FTYPE)s

    #include "mosc.cu"
    #include "mosc3.cu"
    #include "cuda_utils.h"
    #include <stdio.h>

    /* If we use some kind of oversampling then we need the original
     * binning with nebins and nczbins. In the current version we use a
     * fine binning for the first stages and do not need any
     * oversampling.
     */
    __global__ void propagateGrid(fType* d_smooth_maps,
                                  fType d_dm[3][3], fType d_mix[3][3][2],
                                  const fType* const d_ecen_fine,
                                  const fType* const d_czcen_fine,
                                  const int nebins_fine, const int nczbins_fine,
                                  const int nebins, const int nczbins,
                                  const int maxLayers,
                                  const int* const d_numberOfLayers,
                                  const fType* const d_densityInLayer,
                                  const fType* const d_distanceInLayer) {
      const int2 thread_2D_pos = make_int2(blockIdx.x*blockDim.x + threadIdx.x,
                                           blockIdx.y*blockDim.y + threadIdx.y);

      // ensure we don't access memory outside of bounds!
      if (thread_2D_pos.x >= nczbins_fine || thread_2D_pos.y >= nebins_fine)
        return;

      int eidx = thread_2D_pos.y;
      int czidx = thread_2D_pos.x;

      int kNuBar;
      //if (threadIdx.z == 0)
      //  kNuBar = 1;
      if (blockIdx.z == 0)
        kNuBar = 1;
      else
        kNuBar=-1;

      bool kUseMassEstates = false;

      fType TransitionMatrix[3][3][2];
      fType TransitionProduct[3][3][2];
      fType TransitionTemp[3][3][2];
      fType RawInputPsi[3][2];
      fType OutputPsi[3][2];
      fType Probability[3][3];

      clear_complex_matrix(TransitionMatrix);
      clear_complex_matrix(TransitionProduct);
      clear_complex_matrix(TransitionTemp);
      clear_probabilities(Probability);

      //int layers = 1;//*(d_numberOfLayers + czidx);
      int layers = d_numberOfLayers[czidx];

      fType energy = d_ecen_fine[eidx];
      //fType coszen = d_czcen_fine[czidx];
      for (int i=0; i<layers; i++) {
        //fType density = 0.5;//*(d_densityInLayer + czidx*maxLayers + i);
        fType density = d_densityInLayer[czidx*maxLayers + i];
        //fType distance = 100.;//*(d_distanceInLayer + czidx*maxLayers + i);
        fType distance = d_distanceInLayer[czidx*maxLayers + i];

        get_transition_matrix(kNuBar,
                              energy,
                              density,
                              distance,
                              TransitionMatrix,
                              0.0,
                              d_mix,
                              d_dm);

        if (i==0) {
          copy_complex_matrix(TransitionMatrix, TransitionProduct);
        } else {
          clear_complex_matrix(TransitionTemp);
          multiply_complex_matrix(TransitionMatrix, TransitionProduct, TransitionTemp);
          copy_complex_matrix(TransitionTemp, TransitionProduct);
        }
      } // end layer loop

      // loop on neutrino types, and compute probability for neutrino i:
      // We actually don't care about nutau -> anything since the flux there is zero!
      for (unsigned i=0; i<2; i++) {
        for (unsigned j = 0; j < 3; j++) {
          RawInputPsi[j][0] = 0.0;
          RawInputPsi[j][1] = 0.0;
        }

        if (kUseMassEstates)
          convert_from_mass_eigenstate(i+1, kNuBar, RawInputPsi, d_mix);
        else
          RawInputPsi[i][0] = 1.0;

        multiply_complex_matvec(TransitionProduct, RawInputPsi, OutputPsi);
        Probability[i][0] += OutputPsi[0][0]*OutputPsi[0][0] + OutputPsi[0][1]*OutputPsi[0][1];
        Probability[i][1] += OutputPsi[1][0]*OutputPsi[1][0] + OutputPsi[1][1]*OutputPsi[1][1];
        Probability[i][2] += OutputPsi[2][0]*OutputPsi[2][0] + OutputPsi[2][1]*OutputPsi[2][1];
      } // end of neutrino loop

      int efctr = nebins_fine/nebins;
      int czfctr = nczbins_fine/nczbins;
      int eidx_smooth = eidx/efctr;
      int czidx_smooth = czidx/czfctr;
      fType scale = fType(efctr*czfctr);
      for (int i=0;i<2;i++) {
        int iMap = 0;
        if (kNuBar == 1)
          iMap = i*3;
        else
          iMap = 6 + i*3;

        for (unsigned to_nu=0; to_nu<3; to_nu++) {
          int k = (iMap+to_nu);
          fType prob = Probability[i][to_nu];
          atomicAdd_custom((d_smooth_maps + k*nczbins*nebins +
              eidx_smooth*nczbins + czidx_smooth), prob/scale);
        }
      }
    }

    __global__ void propagateArray(fType* d_prob_e,
                                   fType* d_prob_mu,
                                   fType d_dm[3][3],
                                   fType d_mix[3][3][2],
                                   const int n_evts,
                                   const int kNuBar,
                                   const int kFlav,
                                   const int maxLayers,
                                   fType true_e_scale,
                                   const fType* const d_energy,
                                   const int* const d_numberOfLayers,
                                   const fType* const d_densityInLayer,
                                   const fType* const d_distanceInLayer)
    {
      const int idx = blockIdx.x*blockDim.x + threadIdx.x;
      // ensure we don't access memory outside of bounds!
      if(idx >= n_evts) return;
      bool kUseMassEstates = false;
      fType TransitionMatrix[3][3][2];
      fType TransitionProduct[3][3][2];
      fType TransitionTemp[3][3][2];
      fType RawInputPsi[3][2];
      fType OutputPsi[3][2];
      fType Probability[3][3];
      clear_complex_matrix( TransitionMatrix );
      clear_complex_matrix( TransitionProduct );
      clear_complex_matrix( TransitionTemp );
      clear_probabilities( Probability );
      int layers = *(d_numberOfLayers + idx);
      fType energy = d_energy[idx] * true_e_scale;
      for( int i=0; i<layers; i++) {
        fType density = *(d_densityInLayer + idx*maxLayers + i);
        fType distance = *(d_distanceInLayer + idx*maxLayers + i);
        get_transition_matrix(kNuBar,
                              energy,
                              density,
                              distance,
                              TransitionMatrix,
                              0.0,
                              d_mix,
                              d_dm);
        if(i==0) {
          copy_complex_matrix(TransitionMatrix, TransitionProduct);
        } else {
          clear_complex_matrix( TransitionTemp );
          multiply_complex_matrix( TransitionMatrix, TransitionProduct, TransitionTemp );
          copy_complex_matrix( TransitionTemp, TransitionProduct );
        }
      } // end layer loop

      // loop on neutrino types, and compute probability for neutrino i:
      // We actually don't care about nutau -> anything since the flux there is zero!
      for( unsigned i=0; i<2; i++) {
        for ( unsigned j = 0; j < 3; j++ ) {
          RawInputPsi[j][0] = 0.0;
          RawInputPsi[j][1] = 0.0;
        }

        if( kUseMassEstates )
          convert_from_mass_eigenstate(i+1, kNuBar, RawInputPsi, d_mix);
        else
          RawInputPsi[i][0] = 1.0;

        // calculate 'em all here, from legacy code...
        multiply_complex_matvec( TransitionProduct, RawInputPsi, OutputPsi );
        Probability[i][0] +=OutputPsi[0][0]*OutputPsi[0][0]+OutputPsi[0][1]*OutputPsi[0][1];
        Probability[i][1] +=OutputPsi[1][0]*OutputPsi[1][0]+OutputPsi[1][1]*OutputPsi[1][1];
        Probability[i][2] +=OutputPsi[2][0]*OutputPsi[2][0]+OutputPsi[2][1]*OutputPsi[2][1];
      }

      d_prob_e[idx] = Probability[0][kFlav];
      d_prob_mu[idx] = Probability[1][kFlav];

    }
    '''


    def __init__(self, params, input_binning, output_binning,
                 memcache_deepcopy, error_method, transforms_cache_depth,
                 outputs_cache_depth, debug_mode=None, 
                 use_spline=False, spline_binning=None,
                 use_gpu=False, gpu_id=None):

        # If no binning provided then we want to use this to calculate
        # probabilities for events instead of transforms for maps.
        # Set up this self.calc_binned_transforms to use as an assert on the
        # appropriate functions.
        self.calc_binned_transforms = (input_binning is not None and output_binning is not None)
        if ( input_binning is None or output_binning is None ) and ( input_binning != output_binning ):
            raise ValueError('Input and output binning must either both be'
                             ' defined or both be none, but not a mixture.'
                             ' Something is wrong here.')

        #Store GPU info
        self.use_gpu = use_gpu #TODO instead determine if running on a CUDA machine (e.g. check CUDA dvices or similar)
        self.gpu_id = gpu_id
        if ( self.gpu_id is not None ) and ( self.use_gpu is None ) :
            logging.warn("GPU ID has been specified but user has not chosen to use GPUs. Option will be ignored.")

        #Report use options
        if self.calc_binned_transforms :
            logging.debug('User has selected to use prob3 %s to produce binned oscillation transforms' % ("GPU" if self.use_gpu else "CPU") )
        else:
            logging.debug('User has selected to use prob3 %s to calculate event probabilties' % ("GPU" if self.use_gpu else "CPU"))

        # Define the names of objects that are required by this stage (objects
        # will have the attribute `name`: i.e., obj.name)
        input_names = (
            'nue', 'numu', 'nuebar', 'numubar'
        )

        # Define the names of objects that get produced by this stage
        output_names = (
            'nue', 'numu', 'nutau', 'nuebar', 'numubar', 'nutaubar'
        )

        # Invoke the init method from the parent class (Stage), which does a
        # lot of work (caching, providing public interfaces, etc.)
        super(self.__class__, self).__init__(
            use_transforms=True,
            params=params,
            expected_params=self.get_expected_params(self.calc_binned_transforms),
            input_names=input_names,
            output_names=output_names,
            error_method=error_method,
            disk_cache=None,
            outputs_cache_depth=outputs_cache_depth,
            memcache_deepcopy=memcache_deepcopy,
            transforms_cache_depth=transforms_cache_depth,
            input_binning=input_binning,
            output_binning=output_binning,
            debug_mode=debug_mode
        )

        #Compute some useful stuff for the binned transforms before we get started
        if self.calc_binned_transforms:
            self._compute_binning_constants()

        #Vacuum oscillations are only implemented in prob3 CPU
        #Enfroce CPU usage in this case
        if self.params.earth_model is None and self.use_gpu :
            logging.warn("Not GPU prob implementation for vacuum oscillations. Will use a CPU")
            self.use_gpu = False

        #Initialize CUDA usage
        if self.use_gpu :
            self._initialize_kernel()

        #If user specified that a spline should be used for speeding up the calculations, initialise this here
        self.use_spline = use_spline
        if self.use_spline : 
            if spline_binning is None :
                raise Exception("Must provide 'spline_binning' when splining oscillation probabilities")
            self._init_osc_splines(spline_binning)


    def _compute_binning_constants(self):
        
        # Only works if energy and coszen are in input_binning
        if 'true_energy' not in self.input_binning \
                or 'true_coszen' not in self.input_binning:
            raise ValueError(
                'Input binning must contain both "true_energy" and'
                ' "true_coszen" dimensions.'
            )

        # Not handling rebinning (or oversampling)
        assert self.input_binning == self.output_binning

        # Get the energy/coszen (ONLY) weighted centers here, since these
        # are actually used in the oscillations computation. All other
        # dimensions are ignored. Since these won't change so long as the
        # binning doesn't change, attache these to self.
        self.ecz_binning = MultiDimBinning([
            self.input_binning.true_energy.to('GeV'),
            self.input_binning.true_coszen.to('dimensionless')
        ])

        e_centers, cz_centers = self.ecz_binning.weighted_centers
        self.e_centers = e_centers.magnitude
        self.cz_centers = cz_centers.magnitude

        self.num_czbins = self.input_binning.true_coszen.num_bins
        self.num_ebins = self.input_binning.true_energy.num_bins

        self.e_dim_num = self.input_binning.names.index('true_energy')
        self.cz_dim_num = self.input_binning.names.index('true_coszen')

        self.extra_dim_nums = range(self.input_binning.num_dims)
        [self.extra_dim_nums.remove(d) for d in (self.e_dim_num,
                                                 self.cz_dim_num)]


    def _setup_barger_propagator(self):

        #Only used in CPU mode
        if self.use_gpu : return

        # If already instantiated with same parameters, don't instantiate again
        if (hasattr(self, 'barger_propagator')
                and hasattr(self, '_barger_earth_model')
                and hasattr(self, '_barger_detector_depth')
                and (normQuant(self._barger_detector_depth, sigfigs=SIGFIGS)
                     == normQuant(self.params.detector_depth.m_as('km'),
                                  sigfigs=SIGFIGS))
                and self.params.earth_model.value == self._barger_earth_model):
            return

        # Some private variables to keep track of the state of the barger
        # propagator that has been instantiated, so if it is requested to be
        # instantiated again with equivalent parameters, this step can be
        # skipped (see checks above).
        self._barger_detector_depth = self.params.detector_depth.m_as('km')
        self._barger_earth_model = self.params.earth_model.value

        # TODO: can we pass kwargs to swig-ed C++ code?
        if self._barger_earth_model is not None:
            earth_model = find_resource(self._barger_earth_model)
            self.barger_propagator = BargerPropagator(
                earth_model.encode('ascii'),
                self._barger_detector_depth
            )
        else:
            # Initialise with the 12 layer model that should be there. All
            # calculations will use the GetVacuumProb so what we define here
            # doesn't matter.
            self.barger_propagator = BargerPropagator(
                find_resource('osc/PREM_12layer.dat'),
                self._barger_detector_depth
            )
        self.barger_propagator.UseMassEigenstates(False)


    def _derive_nominal_transforms_hash(self):
        """No nominal transforms implemented for this service."""
        return


    @profile
    def _compute_transforms(self):

        #
        # GPU case
        #

        if self.use_gpu :

            import pycuda.driver as cuda

            """Compute oscillation transforms using grid_propagator GPU code."""

            # Read parameters in, convert to the units used internally for
            # computation, and then strip the units off. Note that this also
            # enforces compatible units (but does not sanity-check the numbers).
            theta12 = self.params.theta12.m_as('rad')
            theta13 = self.params.theta13.m_as('rad')
            theta23 = self.params.theta23.m_as('rad')
            deltam21 = self.params.deltam21.m_as('eV**2')
            deltam31 = self.params.deltam31.m_as('eV**2')
            deltacp = self.params.deltacp.m_as('rad')
            YeI = self.params.YeI.m_as('dimensionless')
            YeO = self.params.YeO.m_as('dimensionless')
            YeM = self.params.YeM.m_as('dimensionless')
            prop_height = self.params.prop_height.m_as('km')

            sin2th12Sq = np.sin(theta12)**2
            sin2th13Sq = np.sin(theta13)**2
            sin2th23Sq = np.sin(theta23)**2

            mAtm = deltam31 if deltam31 < 0.0 else (deltam31 - deltam21)

            self.layers = Layers(self.params.earth_model.value,
                                 self.params.detector_depth.m_as('km'),
                                 prop_height)
            self.layers.setElecFrac(YeI, YeO, YeM)
            self.osc = OscParams(deltam21, mAtm, sin2th12Sq, sin2th13Sq,
                                 sin2th23Sq, deltacp)

            self._prepare_device_arrays()

            dm_mat = self.osc.M_mass
            mix_mat = self.osc.M_pmns

            logging.trace('dm_mat: \n %s' %str(dm_mat))
            logging.trace('mix[re]: \n %s' %str(mix_mat[:,:,0]))

            dm_mat = dm_mat.astype(FTYPE)
            mix_mat = mix_mat.astype(FTYPE)

            d_dm_mat = cuda.mem_alloc(dm_mat.nbytes)
            d_mix_mat = cuda.mem_alloc(mix_mat.nbytes)
            cuda.memcpy_htod(d_dm_mat, dm_mat)
            cuda.memcpy_htod(d_mix_mat, mix_mat)

            ne_bin_centers = np.int32(len(self.e_centers)) #TODO use self.num_ebins ??
            ncz_bin_centers = np.int32(len(self.cz_centers)) #TODO use self.num_czbins ??

            # Earlier versions had self.e_centers*energy_scale but energy_scale is
            # not used anymore
            cuda.memcpy_htod(self.d_e_centers, self.e_centers)

            smooth_maps = np.zeros((ncz_bin_centers*ne_bin_centers*12), dtype=FTYPE)
            d_smooth_maps = cuda.mem_alloc(smooth_maps.nbytes)
            cuda.memcpy_htod(d_smooth_maps, smooth_maps)

            block_size = (16, 16, 1)
            grid_size = (
                ncz_bin_centers // block_size[0] + 1,
                ne_bin_centers // block_size[1] + 1,
                2
            )

            self.propGrid(d_smooth_maps,
                          d_dm_mat, d_mix_mat,
                          self.d_e_centers, self.d_cz_centers,
                          ne_bin_centers, ncz_bin_centers,
                          ne_bin_centers, ncz_bin_centers,
                          np.int32(self.maxLayers),
                          self.d_numLayers, self.d_densityInLayer,
                          self.d_distanceInLayer,
                          block=block_size, grid=grid_size)
                          #shared=16384)

            cuda.memcpy_dtoh(smooth_maps, d_smooth_maps)

            # Return TransformSet
            smooth_maps = np.reshape(smooth_maps, (12, ne_bin_centers, ncz_bin_centers))
            # Slice up the transform arrays into views to populate each transform
            dims = ['true_energy', 'true_coszen']
            xform_dim_indices = [0, 1]
            users_dim_indices = [self.input_binning.index(d) for d in dims]
            xform_shape = [2] + [self.input_binning[d].num_bins for d in dims]
            transforms = []
            for out_idx, output_name in enumerate(self.output_names):
                xform = np.empty(xform_shape)
                if out_idx < 3:
                    # Neutrinos
                    xform[0] = smooth_maps[out_idx]
                    xform[1] = smooth_maps[out_idx+3]
                    input_names = self.input_names[0:2]
                else:
                    # Antineutrinos
                    xform[0] = smooth_maps[out_idx+3]
                    xform[1] = smooth_maps[out_idx+6]
                    input_names = self.input_names[2:4]

                xform = np.moveaxis(
                    xform,
                    source=[0] + [i+1 for i in xform_dim_indices],
                    destination=[0] + [i+1 for i in users_dim_indices]
                )
                transforms.append(
                    BinnedTensorTransform(
                        input_names=input_names,
                        output_name=output_name,
                        input_binning=self.input_binning,
                        output_binning=self.input_binning,
                        xform_array=xform
                    )
                )


        #
        # CPU case
        #

        else :

            """Compute oscillation transforms using Prob3 CPU code."""
            self._setup_barger_propagator()

            # Read parameters in, convert to the units used internally for
            # computation, and then strip the units off. Note that this also
            # enforces compatible units (but does not sanity-check the numbers).
            theta12 = self.params.theta12.m_as('rad')
            theta13 = self.params.theta13.m_as('rad')
            theta23 = self.params.theta23.m_as('rad')
            deltam21 = self.params.deltam21.m_as('eV**2')
            deltam31 = self.params.deltam31.m_as('eV**2')
            deltacp = self.params.deltacp.m_as('rad')
            prop_height = self.params.prop_height.m_as('km')
            nutau_norm = self.params.nutau_norm.m_as('dimensionless')

            # The YeX will not be in params if the Earth model is None
            if self._barger_earth_model is not None:
                YeI = self.params.YeI.m_as('dimensionless')
                YeO = self.params.YeO.m_as('dimensionless')
                YeM = self.params.YeM.m_as('dimensionless')

                total_bins = int(len(self.e_centers)*len(self.cz_centers))
                # We use 18 since we have 3*3 possible oscillations for each of
                # neutrinos and antineutrinos.
                prob_list = np.empty(total_bins*18, dtype='double')
                
                # The 1.0 was energyscale from earlier versions. Perhaps delete this
                # if we no longer want energyscale.
                prob_list, evals, czvals = self.barger_propagator.fill_osc_prob_c(
                    self.e_centers, self.cz_centers, 1.0,
                    deltam21, deltam31, deltacp,
                    prop_height,
                    YeI, YeO, YeM,
                    total_bins*18, total_bins, total_bins,
                    theta12, theta13, theta23
                )
            else:
                # Code copied from BargerPropagator.cc but fill_osc_prob_c but
                # pythonised and modified to use the python binding to
                # GetVacuumProb.
                prob_list = self._get_vacuum_prob_maps(
                    deltam21, deltam31, deltacp,
                    prop_height,
                    theta12, theta13, theta23
                )

            # Slice up the transform arrays into views to populate each transform
            dims = ['true_energy', 'true_coszen']
            xform_dim_indices = [0, 1]
            users_dim_indices = [self.input_binning.index(d) for d in dims]
            xform_shape = [2] + [self.input_binning[d].num_bins for d in dims]

            # TODO: populate explicitly by flavor, don't assume any particular
            # ordering of the outputs names!
            transforms = []
            for out_idx, output_name in enumerate(self.output_names):
                xform = np.empty(xform_shape)
                if out_idx < 3:
                    # Neutrinos
                    xform[0] = np.array([
                        prob_list[out_idx + 18*i*self.num_czbins
                                  : out_idx + 18*(i+1)*self.num_czbins
                                  : 18]
                        for i in range(0, self.num_ebins)
                    ])
                    xform[1] = np.array([
                        prob_list[out_idx+3 + 18*i*self.num_czbins
                                  : out_idx+3 + 18*(i+1)*self.num_czbins
                                  : 18]
                        for i in range(0, self.num_ebins)
                    ])
                    input_names = self.input_names[0:2]

                else:
                    # Antineutrinos
                    xform[0] = np.array([
                        prob_list[out_idx+6 + 18*i*self.num_czbins
                                  : out_idx+6 + 18*(i+1)*self.num_czbins
                                  : 18]
                        for i in range(0, self.num_ebins)
                    ])
                    xform[1] = np.array([
                        prob_list[out_idx+9 + 18*i*self.num_czbins
                                  : out_idx+9 + 18*(i+1)*self.num_czbins
                                  : 18]
                        for i in range(0, self.num_ebins)
                    ])
                    input_names = self.input_names[2:4]

                xform = np.moveaxis(
                    xform,
                    source=[0] + [i+1 for i in xform_dim_indices],
                    destination=[0] + [i+1 for i in users_dim_indices]
                )
                if nutau_norm != 1 and output_name in ['nutau', 'nutaubar']:
                    xform *= nutau_norm
                transforms.append(
                    BinnedTensorTransform(
                        input_names=input_names,
                        output_name=output_name,
                        input_binning=self.input_binning,
                        output_binning=self.output_binning,
                        xform_array=xform
                    )
                )

        return TransformSet(transforms=transforms)


    def _get_vacuum_prob_maps(self, deltam21, deltam31, deltacp, prop_height,
                             theta12, theta13, theta23):

        """
        Calculate oscillation probabilities in the case of vacuum oscillations
        Here we use Prob3 but only because it has already implemented the 
        vacuum oscillations and so makes life easier.
        """

        # Set up oscillation parameters needed to initialise MNS matrix
        kSquared = True
        sin2th12Sq = np.sin(theta12)*np.sin(theta12)
        sin2th13Sq = np.sin(theta13)*np.sin(theta13)
        sin2th23Sq = np.sin(theta23)*np.sin(theta23)
        if deltam31 < 0.0:
            mAtm = deltam31
        else:
            mAtm = deltam31 - deltam21
        # Initialise objects to look over for neutrino and antineutrino flavours
        # 1 - nue, 2 - numu, 3 - nutau
        nuflavs = [1,2,3]
        nubarflavs = [-1,-2,-3]
        prob_list = []
        # Set up the distance to the detector. Radius of Earth is 6371km and
        # we then account for the depth of the detector in the Earth.
        depth = self.params.detector_depth.m_as('km')
        rdetector = 6371.0 - depth
        # Probability is separately calculated for each energy and zenith bin
        # center as well as every initial and final neutrno flavour.
        for e_cen in self.e_centers:
            for cz_cen in self.cz_centers:
                # Neutrinos are calculated for first
                kNuBar = 1
                for alpha in nuflavs:
                    for beta in nuflavs:
                        path = self.calc_path(
                            coszen=cz_cen,
                            rdetector=rdetector,
                            prop_height=prop_height,
                            depth=depth
                        )
                        self.barger_propagator.SetMNS(
                            sin2th12Sq,sin2th13Sq,sin2th23Sq,deltam21,
                            mAtm,deltacp,e_cen,kSquared,kNuBar
                        )
                        prob_list.append(
                            self.barger_propagator.GetVacuumProb(
                                alpha, beta, e_cen, path
                            )
                        )
                # Then antineutrinos. With this, the layout of this prob_list
                # matches the output of the matter oscillations calculation.
                kNuBar = -1
                for alpha in nubarflavs:
                    for beta in nubarflavs:
                        path = self.calc_path(
                            coszen=cz_cen,
                            rdetector=rdetector,
                            prop_height=prop_height,
                            depth=depth
                        )
                        self.barger_propagator.SetMNS(
                            sin2th12Sq,sin2th13Sq,sin2th23Sq,deltam21,
                            mAtm,deltacp,e_cen,kSquared,kNuBar
                        )
                        prob_list.append(
                            self.barger_propagator.GetVacuumProb(
                                alpha, beta, e_cen, path
                            )
                        )
        return prob_list


    def calc_path(self, coszen, rdetector, prop_height, depth):

        """
        Calculates the path through a spherical body of radius rdetector for
        a neutrino coming in with at coszen from prop_height to a detector
        at detph.
        """

        if coszen < 0:
            path = np.sqrt(
                (rdetector + prop_height + depth) * \
                (rdetector + prop_height + depth) - \
                (rdetector*rdetector)*(1 - coszen*coszen)
            ) - rdetector*coszen
        else:
            kappa = (depth + prop_height)/rdetector
            path = rdetector * np.sqrt(
                coszen*coszen - 1 + (1 + kappa)*(1 + kappa)
            ) - rdetector*coszen
        return path
    

    def calc_probs(self, kNuBar, kFlav, n_evts, true_e_scale, true_energy,true_coszen, prob_e, prob_mu, **kwargs):

        """
        Calculate oscillation probabilities event-by-event
        Both vacuum oscillations and propagation through matter are handled
        Both event-by-event calculation and pre-computed splines can be used
        """

        #Check user called the correct function
        self._check_in_event_reweight_mode()

        #Choose between spline or full event-by-event calculation
        if self.use_spline :

            #Check spline has been produced
            if self.prob_e_splines[kFlav][kNuBar] is None :
                raise Exception("Cannot calculate probabilty using spline : Spline has not been generated yet")

            #Extract probabilities for these events from the spline
            np.copyto( prob_e, self.prob_e_splines[kFlav][kNuBar].ev(true_energy,true_coszen) ) #Use copyto to fill np array from another (using '=' sets the pointer reference without changing the underlying object)
            np.copyto( prob_mu, self.prob_mu_splines[kFlav][kNuBar].ev(true_energy,true_coszen) ) 


        else :

            #Calculate probability for every event individually
            self._calc_probs_inner(kNuBar=kNuBar, 
                            kFlav=kFlav, 
                            n_evts=n_evts,
                            true_e_scale=true_e_scale, 
                            true_energy=true_energy, 
                            true_coszen=true_coszen, 
                            prob_e=prob_e, 
                            prob_mu=prob_mu, 
                            **kwargs)



    def _calc_probs_inner(self, kNuBar, kFlav, n_evts, true_e_scale, true_energy,true_coszen, prob_e, prob_mu, **kwargs):


        """
        Calculate oscillation probabilities event-by-event
        Both vacuum oscillations and propagation through matter are handled
        Users should call `calc_probs`, not this function directly
        """

        #
        # GPU case
        #

        if self.use_gpu : 

            #Get relevent kwarghs
            numLayers = kwargs.pop("numLayers")
            densityInLayer = kwargs.pop("densityInLayer")
            distanceInLayer = kwargs.pop("distanceInLayer")

            bdim = (32, 1, 1)
            dx, mx = divmod(n_evts, bdim[0])
            gdim = ((dx + (mx > 0)) * bdim[0], 1)

            self.propArray(
                prob_e,
                prob_mu,
                self.d_dm_mat,
                self.d_mix_mat,
                n_evts,
                np.int32(kNuBar),
                np.int32(kFlav),
                np.int32(self.maxLayers),
                FTYPE(true_e_scale),
                true_energy,
                numLayers,
                densityInLayer,
                distanceInLayer,
                block=bdim,
                grid=gdim
            )

        #
        # CPU case
        #

        else :

            self._setup_barger_propagator()

            # Set up oscillation parameters needed to initialise MNS matrix
            kSquared = True
            theta12 = self.params['theta12'].value.m_as('rad')
            theta13 = self.params['theta13'].value.m_as('rad')
            theta23 = self.params['theta23'].value.m_as('rad')
            deltam21 = self.params['deltam21'].value.m_as('eV**2')
            deltam31 = self.params['deltam31'].value.m_as('eV**2')
            deltacp = self.params['deltacp'].value.m_as('rad')
            sin2th12Sq = np.sin(theta12)*np.sin(theta12)
            sin2th13Sq = np.sin(theta13)*np.sin(theta13)
            sin2th23Sq = np.sin(theta23)*np.sin(theta23)
            if deltam31 < 0.0:
                mAtm = deltam31
            else:
                mAtm = deltam31 - deltam21
            if self._barger_earth_model is None:
                logging.debug("Calculating vacuum oscillations")
                # Set up the distance to the detector. Radius of Earth is 6371km and
                # we then account for the depth of the detector in the Earth.
                depth = self.params.detector_depth.m_as('km')
                prop_height = self.params.prop_height.m_as('km')
                rdetector = 6371.0 - depth
                # Probability is separately calculated for each event
                for i, (en, cz) in enumerate(zip(true_energy,true_coszen)):
                    en *= true_e_scale
                    path = self.calc_path(
                        coszen=cz,
                        rdetector=rdetector,
                        prop_height=prop_height,
                        depth=depth
                    )
                    self.barger_propagator.SetMNS(
                        sin2th12Sq,sin2th13Sq,sin2th23Sq,deltam21,
                        mAtm,deltacp,en,kSquared,events_dict['kNuBar']
                    )
                    # kFlav is zero-start indexed (as the GPU Prob3 version wants it(, whereas Prob3 CPU wants it from 1
                    prob_e[i] = self.barger_propagator.GetVacuumProb(1, kFlav+1, en, path)
                    prob_mu[i] = self.barger_propagator.GetVacuumProb(2, kFlav+1, en, path)
            else:
                logging.debug("Calculating matter oscillations")
                YeI = self.params.YeI.m_as('dimensionless')
                YeO = self.params.YeO.m_as('dimensionless')
                YeM = self.params.YeM.m_as('dimensionless')
                depth = self.params.detector_depth.m_as('km')
                prop_height = self.params.prop_height.m_as('km')

                # Probability is separately calculated for each event
                #for i, (en, cz) in enumerate(zip(true_energy,true_coszen)):
                for i in np.ndindex(true_energy.shape):
                    en = true_energy[i] * true_e_scale
                    cz = true_coszen[i]
                    #en *= true_e_scale
                    self.barger_propagator.SetMNS(
                        sin2th12Sq,sin2th13Sq,sin2th23Sq,deltam21,
                        mAtm,deltacp,en,kSquared,kNuBar
                    )
                    self.barger_propagator.DefinePath(
                        float(cz), prop_height, YeI, YeO, YeM
                    )
                    self.barger_propagator.propagate(kNuBar)
                    prob_e[i] = self.barger_propagator.GetProb(0, kFlav)
                    prob_mu[i] = self.barger_propagator.GetProb(1, kFlav)


    def _init_osc_splines(self,spline_binning) :

        #TODO GPU prob3 code can only handle 1D input arrays, need to udate this to handle that case
        if self.use_gpu :
          raise Exception("Oscillation probability splining not yet supported for GPUs")

        #Initialise everything we are going to need to generate oscillation prbability splines

        #TODO enforce energy bins > 0 (get NaN for E=0)
        #TODO enforce grid dims > spline k

        #Store the bins
        self.spline_binning = spline_binning

        #Get [E,coszen] grid
        self.spline_true_energy_grid, self.spline_true_coszen_grid = np.meshgrid(self.spline_binning["true_energy"].bin_edges.astype(FTYPE),
                                                                                self.spline_binning["true_coszen"].bin_edges.astype(FTYPE),
                                                                                indexing='ij')

        #Create empty probability grids to fill (default to NaN so get errors if not filled correctly)
        self.prob_e_grid = np.full( self.spline_true_energy_grid.shape, np.NaN, dtype=FTYPE )
        self.prob_mu_grid = np.full( self.spline_true_energy_grid.shape, np.NaN, dtype=FTYPE )

        #Define nu/nubar and flavors #TODO (Tom) Get from somwhere else, e.g. flavInt.py
        kNuBar_vals = [-1,1]
        kFlav_vals = [0,1,2]

        #Create container for splines that we are about to generate
        #Outer key is flavor, inner key is nu/nubar
        self.prob_e_splines = dict([ ( kFlav, dict([ (kNuBar,None) for kNuBar in kNuBar_vals]) ) for kFlav in kFlav_vals ])
        self.prob_mu_splines = dict([ ( kFlav, dict([ (kNuBar,None) for kNuBar in kNuBar_vals]) ) for kFlav in kFlav_vals ])

        #For GPU case, need to copy grid point values to device
        #TODO 


        #Store anything else that we will need later
        self.spline_prob_calc_args = dict()
        if self.use_gpu : #GPU case needs pre-computed layer information
          raise Exception("TODO Need to caluclate layers 'per flavor'") #TODO
          self.spline_prob_calc_args['numLayers'],self.spline_prob_calc_args['densityInLayer'],self.spline_prob_calc_args['distanceInLayer'] = self.calc_layers(self.spline_binning["true_coszen"].bin_edges.astype(FTYPE))


    def generate_osc_splines(self,true_e_scale) :

        #TODO (Tom)-> helper function so can generically use in CPU or GPU code
        #TODO (Tom) Add logic in this class to determine whether splines need regenerating? Currently is the resonsiblity of the calling code (such as weight.py)

        #TODO (Tom) Handle true_e_scale
        if not np.isclose(true_e_scale,1.) : raise NotImplementedError("generate_osc_splines cannot currently handle true_e_scale != 1., this needs implementing")

        #Scale energy parameters
        #TODO (Tom) test this
        scaled_true_energy_grid = true_e_scale * self.spline_true_energy_grid
        scaled_true_e_bins = true_e_scale * self.spline_binning["true_energy"].bin_edges

        #Loop over nu vs nubar and nu flavors
        kFlav_vals = self.prob_e_splines.keys()
        for kFlav in kFlav_vals :
            kNuBar_vals = self.prob_e_splines[kFlav].keys()
            for kNuBar in kNuBar_vals :

                #Calculate probabilites for grid
                self._calc_probs_inner( kNuBar=kNuBar, 
                                kFlav=kFlav, 
                                n_evts=np.int32(len(scaled_true_energy_grid)),
                                true_e_scale=true_e_scale, 
                                true_energy=scaled_true_energy_grid, 
                                true_coszen=self.spline_true_coszen_grid, 
                                prob_e=self.prob_e_grid, 
                                prob_mu=self.prob_mu_grid,
                                **self.spline_prob_calc_args )

                # Spline it for smoothing
                self.prob_e_splines[kFlav][kNuBar] = RectBivariateSpline( scaled_true_e_bins, self.spline_binning["true_coszen"].bin_edges, self.prob_e_grid )
                self.prob_mu_splines[kFlav][kNuBar] = RectBivariateSpline( scaled_true_e_bins, self.spline_binning["true_coszen"].bin_edges, self.prob_mu_grid )


    def create_transforms_datastructs(self): #TODO (Tom) is this deprecated?
        xform_shape = [3, 2] + list(self.input_binning.shape)
        nu_xform = np.empty(xform_shape)
        antinu_xform = np.empty(xform_shape)
        return nu_xform, antinu_xform


    def _initialize_kernel(self):

        #Perform CUDA imports here (so that we don't need CUDA when using CPUs)
        import pycuda.autoinit
        import pycuda.compiler 

        """Initialize 1) the grid_propagator class, 2) the device arrays that
        will be passed to the `propagateGrid()` kernel, and 3) the kernel
        module.

        """
        # Path relative to `resources` directory
        include_dirs = [
            os.path.abspath(find_resource('../stages/osc/prob3cuda')),
            os.path.abspath(find_resource('../utils'))
        ]
        logging.debug('  pycuda INC PATH: %s' %include_dirs)
        logging.debug('  pycuda FLAGS: %s' %pycuda.compiler.DEFAULT_NVCC_FLAGS)

        kernel_code = (self.KERNEL_TEMPLATE
                       %dict(C_PRECISION_DEF=C_PRECISION_DEF, C_FTYPE=C_FTYPE))

        self.module = pycuda.compiler.SourceModule(
            kernel_code, include_dirs=include_dirs, keep=True
        )
        if not self.calc_binned_transforms:
            self.propArray = self.module.get_function('propagateArray')
        else:
            self.propGrid = self.module.get_function('propagateGrid')


    def _prepare_device_arrays(self):

        import pycuda.driver as cuda

        self.layers.calcLayers(self.cz_centers)
        self.maxLayers = self.layers.max_layers

        numLayers = self.layers.n_layers
        densityInLayer = self.layers.density
        distanceInLayer = self.layers.distance

        numLayers = numLayers.astype(np.int32)
        densityInLayer = densityInLayer.astype(FTYPE)
        distanceInLayer = distanceInLayer.astype(FTYPE)
        # Copy all these earth info arrays to device:
        self.d_numLayers = cuda.mem_alloc(numLayers.nbytes)
        self.d_densityInLayer = cuda.mem_alloc(densityInLayer.nbytes)
        self.d_distanceInLayer = cuda.mem_alloc(distanceInLayer.nbytes)
        cuda.memcpy_htod(self.d_numLayers, numLayers)
        cuda.memcpy_htod(self.d_densityInLayer, densityInLayer)
        cuda.memcpy_htod(self.d_distanceInLayer, distanceInLayer)

        self.d_e_centers = cuda.mem_alloc(self.e_centers.nbytes)
        self.d_cz_centers = cuda.mem_alloc(self.cz_centers.nbytes)
        cuda.memcpy_htod(self.d_e_centers, self.e_centers)
        cuda.memcpy_htod(self.d_cz_centers, self.cz_centers)


    def _free_device_memory(self):

        self.d_numLayers.free()
        self.d_densityInLayer.free()
        self.d_distanceInLayer.free()

        self.d_e_centers.free()
        self.d_cz_centers.free()


    def update_MNS(self, theta12, theta13, theta23,
                   deltam21, deltam31, deltacp):

        """
        Returns an oscillation probability map dictionary calculated
        at the values of the input parameters:
          deltam21, deltam31, theta12, theta13, theta23, deltacp
          * theta12, theta13, theta23 - in [rad]
          * deltam21, deltam31 - in [eV^2]
        """

        #Check user called the correct function
        self._check_in_event_reweight_mode()

        #Only used in GPU mode
        if not self.use_gpu : return

        import pycuda.driver as cuda

        sin2th12Sq = np.sin(theta12)**2
        sin2th13Sq = np.sin(theta13)**2
        sin2th23Sq = np.sin(theta23)**2

        mAtm = deltam31 if deltam31 < 0.0 else (deltam31 - deltam21)

        # Comment BargerPropagator.cc::SetMNS()
        # "For the inverted Hierarchy, adjust the input
        # by the solar mixing (should be positive)
        # to feed the core libraries the correct value of m32."
        #if mAtm < 0.0: mAtm -= deltam21;

        self.osc = OscParams(deltam21, mAtm, sin2th12Sq, sin2th13Sq, sin2th23Sq, deltacp)
        dm_mat = self.osc.M_mass
        mix_mat = self.osc.M_pmns

        logging.debug("dm_mat: \n %s"%str(dm_mat))
        logging.debug("mix[re]: \n %s"%str(mix_mat[:,:,0]))

        self.d_dm_mat = cuda.mem_alloc(FTYPE(dm_mat).nbytes)
        self.d_mix_mat = cuda.mem_alloc(FTYPE(mix_mat).nbytes)
        cuda.memcpy_htod(self.d_dm_mat, FTYPE(dm_mat))
        cuda.memcpy_htod(self.d_mix_mat, FTYPE(mix_mat))


    def calc_layers(self, coszen):
        """
        \params:
          * energy: array of energies in GeV
          * coszen: array of coszen values
          * kNuBar: +1 for neutrinos, -1 for anti neutrinos
          * earth_model: Earth density model used for matter oscillations.
          * detector_depth: Detector depth in km.
          * prop_height: Height in the atmosphere to begin in km.
        """

        #Check user called the correct function
        self._check_in_event_reweight_mode()

        #Only used in GPU mode
        if not self.use_gpu : return None, None, None

        YeI = self.params.YeI.m_as('dimensionless')
        YeO = self.params.YeO.m_as('dimensionless')
        YeM = self.params.YeM.m_as('dimensionless')
        prop_height = self.params.prop_height.m_as('km')
        self.layers = Layers(self.params.earth_model.value, self.params.detector_depth.m_as('km'), prop_height)
        self.layers.setElecFrac(YeI, YeO, YeM)

        self.layers.calcLayers(coszen)
        self.maxLayers = self.layers.max_layers #Note that max layers depends on earth model obly (e.g. do not need to store a different value per flav-int)

        numLayers = self.layers.n_layers
        densityInLayer = self.layers.density
        distanceInLayer = self.layers.distance

        numLayers = numLayers.astype(np.int32)
        densityInLayer = densityInLayer.astype(FTYPE)
        distanceInLayer = distanceInLayer.astype(FTYPE)

        return numLayers, densityInLayer, distanceInLayer


    #Flag indicating that we are using event re-weighting (inverse of use_binned_transforms)
    @property
    def calc_event_probs(self) : 
        return not self.calc_binned_transforms

    #Check that the user has called a suitable function for the current mode
    #Some functions are specific to PISA map re-weigting, whilst some are for event re-weighting
    def _check_in_binned_transform_mode(self) :
        if not self.calc_binned_transforms :
            raise ValueError("You have initialised prob3 for the case of event re-weighting, but called a function intended for use binned transforms with PISA maps")

    def _check_in_event_reweight_mode(self) :
        if not self.calc_event_probs :
            raise ValueError("You have initialised prob3 for the case of binned transforms with PISA maps, but called a function intended for use when re-weighting events")


    #Static function for getting expected params
    #Implemented like this so external code can access this information (for example oscilogram plotters which may instantiate this class)
    @staticmethod
    def get_expected_params(calc_binned_transforms) :

        #Define expected params and return them as a list
        #Depends on whether performing PISA map or event-by-event calculation
        #In the current implementation, this does not depend on whether using a CPU or GPU implementation of prob3

        #Start by defining the params common to all cases
        expected_params = [
            'earth_model', 'YeI', 'YeM', 'YeO',
            'detector_depth', 'prop_height',
            'deltacp', 'deltam21', 'deltam31',
            'theta12', 'theta13', 'theta23',
            ]

        #Binned transform case applies a nutau norm factor (handled differently for event re-weighting case)
        if calc_binned_transforms :
            expected_params.append('nutau_norm')

        #TODO (Tom) true_e_scale? Is included in the old code, but it looks to be like it is never used as a param, and instead the value is taken as an arg to calc_probs? Should true_e_scale be a param as used as one, or an arg? Probably a param...

        #In event re-weighting mode, has moptio of not oscillating NC events to save time (their rate should be conserved)
        if not calc_binned_transforms :
            expected_params.append('no_nc_osc')

        return tuple(expected_params)



    def validate_params(self, params):
        if params['earth_model'].value is None:
            if params['YeI'].value is not None:
                raise ValueError("A none Earth model has been set but the YeI "
                                 "value is set to %s. Set this to none."
                                 %params['YeI'].value)
            if params['YeO'].value is not None:
                raise ValueError("A none Earth model has been set but the YeO "
                                 "value is set to %s. Set this to none."
                                 %params['YeO'].value)
            if params['YeM'].value is not None:
                raise ValueError("A none Earth model has been set but the YeM "
                                 "value is set to %s. Set this to none."
                                 %params['YeM'].value)
        pass

